"""
Script để test với malware samples
CẢNH BÁO: Chỉ chạy trong môi trường cách ly (sandbox/VM)
"""

import argparse
import sys
from pathlib import Path
import logging
import pickle
import numpy as np

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.features.static import OpcodeExtractor, CFGExtractor, APIExtractor
from src.features.feature_combiner import FeatureCombiner
from src.models import RandomForestModel, XGBoostModel, NeuralNetworkModel

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def extract_features_from_sample(file_path: str) -> dict:
    """
    Trích xuất features từ một sample
    
    Args:
        file_path: Path to sample file
        
    Returns:
        Dictionary of features
    """
    logger.info(f"Extracting features from {file_path}...")
    
    extractors = {
        'opcode': OpcodeExtractor(n_grams=[2, 3, 4]),
        'cfg': CFGExtractor(),
        'api': APIExtractor()
    }
    combiner = FeatureCombiner()
    
    all_features = {}
    
    # Opcode features
    try:
        with open(file_path, 'rb') as f:
            binary_data = f.read()
        opcode_features = extractors['opcode'].extract_features(binary_data, max_features=1000)
        all_features.update(opcode_features)
    except Exception as e:
        logger.warning(f"Error extracting opcodes: {e}")
    
    # CFG features
    try:
        cfg_features = extractors['cfg'].extract_features(file_path)
        all_features.update(cfg_features)
    except Exception as e:
        logger.warning(f"Error extracting CFG: {e}")
    
    # API features
    try:
        api_features = extractors['api'].extract_api_features(file_path, max_features=500)
        all_features.update(api_features)
    except Exception as e:
        logger.warning(f"Error extracting APIs: {e}")
    
    # Combine
    combined = combiner.combine(all_features)
    
    return {
        'features': combined,
        'feature_names': combiner.get_feature_names(),
        'raw_features': all_features
    }


def predict_with_model(model_path: str, model_type: str, features: dict) -> dict:
    """
    Dự đoán với model đã train
    
    Args:
        model_path: Path to trained model
        model_type: Type of model
        features: Extracted features
        
    Returns:
        Prediction results
    """
    logger.info(f"Loading {model_type} model from {model_path}...")
    
    # Load model
    if model_type == 'random_forest':
        model = RandomForestModel()
    elif model_type == 'xgboost':
        model = XGBoostModel()
    elif model_type == 'neural_network':
        model = NeuralNetworkModel()
    else:
        raise ValueError(f"Unknown model type: {model_type}")
    
    model.load(model_path)
    
    # Get expected feature dimension from model
    expected_dim = None
    if model_type == 'random_forest':
        if hasattr(model.model, 'n_features_in_'):
            expected_dim = model.model.n_features_in_
        elif hasattr(model.model, 'feature_importances_'):
            expected_dim = len(model.model.feature_importances_)
    elif model_type == 'xgboost':
        try:
            expected_dim = model.model.get_booster().num_feature()
        except:
            if hasattr(model.model, 'feature_importances_'):
                expected_dim = len(model.model.feature_importances_)
    elif model_type == 'neural_network':
        # Neural network models store input_size when saved
        if hasattr(model, 'input_size'):
            expected_dim = model.input_size
        else:
            # Try to get from first layer as fallback
            try:
                first_layer = list(model.model.modules())[1]  # Skip the container module
                if hasattr(first_layer, 'in_features'):
                    expected_dim = first_layer.in_features
            except:
                pass
    
    if expected_dim is None:
        logger.warning("Could not determine expected feature dimension from model. Using extracted features as-is.")
        expected_dim = len(features['features'])
    
    logger.info(f"Model expects {expected_dim} features, extracted {len(features['features'])} features")
    
    # Prepare feature vector
    feature_vector = features['features'].reshape(1, -1)
    
    # Align features to match model input size
    current_dim = feature_vector.shape[1]
    if current_dim < expected_dim:
        # Pad with zeros
        padding = np.zeros((1, expected_dim - current_dim))
        feature_vector = np.hstack([feature_vector, padding])
        logger.info(f"Padded features from {current_dim} to {expected_dim}")
    elif current_dim > expected_dim:
        # Truncate
        feature_vector = feature_vector[:, :expected_dim]
        logger.info(f"Truncated features from {current_dim} to {expected_dim}")
    
    # Predict
    prediction = model.predict(feature_vector)[0]
    probabilities = model.predict_proba(feature_vector)[0]
    
    # Handle case where model only has 1 class (single-class prediction)
    num_classes = len(probabilities)
    
    if num_classes == 1:
        # Model only predicts one class (likely all samples are same class)
        logger.warning("Model only has 1 class. This may indicate dataset imbalance.")
        # Assume it's predicting the class it was trained on
        if prediction == 0:
            prob_benign = float(probabilities[0])
            prob_obfuscated = 1.0 - prob_benign
            pred_label = 'Benign'
        else:
            prob_obfuscated = float(probabilities[0])
            prob_benign = 1.0 - prob_obfuscated
            pred_label = 'Obfuscated'
    elif num_classes == 2:
        # Normal case: 2 classes
        prob_benign = float(probabilities[0])
        prob_obfuscated = float(probabilities[1])
        pred_label = 'Obfuscated' if prediction == 1 else 'Benign'
    else:
        # More than 2 classes (unexpected, but handle it)
        logger.warning(f"Model has {num_classes} classes, expected 2")
        prob_benign = float(probabilities[0]) if len(probabilities) > 0 else 0.0
        prob_obfuscated = float(probabilities[1]) if len(probabilities) > 1 else 0.0
        pred_label = 'Obfuscated' if prediction == 1 else 'Benign'
    
    return {
        'prediction': pred_label,
        'confidence': float(max(prob_benign, prob_obfuscated)),
        'probabilities': {
            'benign': prob_benign,
            'obfuscated': prob_obfuscated
        },
        'model_type': model_type,
        'num_classes': num_classes
    }


def main():
    parser = argparse.ArgumentParser(
        description="Test malware sample với trained models",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
⚠️  CẢNH BÁO BẢO MẬT:
- Chỉ chạy script này trong môi trường cách ly (sandbox/VM)
- Không chạy trên hệ thống production
- Tuân thủ các quy định pháp lý về phân tích malware
        """
    )
    
    parser.add_argument('sample', type=str, help='Path to sample file to analyze')
    parser.add_argument('--model', type=str, required=True, help='Path to trained model')
    parser.add_argument('--model-type', type=str, required=True,
                       choices=['random_forest', 'xgboost', 'neural_network'],
                       help='Type of model')
    parser.add_argument('--output', type=str, help='Output file for results (JSON)')
    
    args = parser.parse_args()
    
    # Check if sample exists
    if not Path(args.sample).exists():
        logger.error(f"Sample file not found: {args.sample}")
        return
    
    # Extract features
    features = extract_features_from_sample(args.sample)
    
    if len(features['features']) == 0:
        logger.error("No features extracted!")
        return
    
    logger.info(f"Extracted {len(features['features'])} features")
    
    # Predict
    results = predict_with_model(args.model, args.model_type, features)
    
    # Print results
    print("\n" + "="*50)
    print("KẾT QUẢ PHÂN TÍCH")
    print("="*50)
    print(f"File: {args.sample}")
    print(f"Kết quả: {results['prediction']}")
    print(f"Độ tin cậy: {results['confidence']*100:.2f}%")
    print(f"Xác suất Benign: {results['probabilities']['benign']*100:.2f}%")
    print(f"Xác suất Obfuscated: {results['probabilities']['obfuscated']*100:.2f}%")
    print(f"Model: {results['model_type']}")
    print("="*50)
    
    # Save results if output specified
    if args.output:
        import json
        output_data = {
            'sample': args.sample,
            'results': results,
            'feature_count': len(features['features'])
        }
        with open(args.output, 'w') as f:
            json.dump(output_data, f, indent=2)
        logger.info(f"Results saved to {args.output}")


if __name__ == "__main__":
    main()

